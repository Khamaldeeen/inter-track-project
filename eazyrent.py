# -*- coding: utf-8 -*-
"""eazyrent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JH64NlJEJSxY0hlgXeQ2lpuVKpG0_f7R
"""

# import libraries
import requests
from bs4 import BeautifulSoup
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from requests import get
import numpy as np
import time
from time import sleep

base_url = 'https://www.propertypro.ng/property-for-rent/in/lagos'
headers =  {'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Mobile Safari/537.36'}

#  Requesting the data  from url.
r = requests.get(base_url, headers=headers)
r.status_code

soup = BeautifulSoup(r.text,'html.parser')
print(soup.title.get_text())

titles = soup.select('.single-room-text > a > h2')

len(titles)

titles_list = []
for title in titles:
    title = title.get_text()
    title = title.split()
    title = title[0:3]
    title = ' '.join(title)
    titles_list.append(title)
titles_list

# find all prices
prices = soup.select('.n50 > h3 > span')

# fixing all prices
prices_list = []
for i, price in enumerate(prices):
    price = price.get_text()
    if len(price)> 2:
        price = price.replace(',','')
        try :
            price = int(price)
        except ValueError:
            price = str(price)    
        prices_list.append(price)

len(prices)

prices_list

locations = soup.select('.single-room-text > h4')

len(locations)

locations_list = []
for i in locations:
    loc = i.get_text().split()
    loc = loc[-2]
    loc = loc.replace(',', '')
    locations_list.append(loc)
locations_list

Amenities = soup.select('.fur-areea > span')

len(Amenities)

Amenities[3].text

toilet_list = []
bath_list = []
bed_list = []

for i, a in enumerate(Amenities):
    if i in range(2,66,3):
        a = a.get_text().split()
        toilet = a[0]
        toilet_list.append(toilet)
    elif i in range(1,66,3):
        a = a.get_text().split()
        bath = a[0]
        bath_list.append(bath)
    elif i in range (0,66,3):
        a = a.get_text().split()
        bed = a[0]
        bed_list.append(bed)

toilet_list

len(toilet_list)

bath_list

len(bath_list)

bed_list

len(bed_list)

#creating a function to be able to return all list generated

def scrape_page(url):
    req = requests.get (base_url, headers=headers)
    soup = BeautifulSoup(r.text,'html.parser')
    
    titles = soup.select('.single-room-text > a > h2')
    titles_list = []
    for title in titles:
        title = title.get_text()
    title = title.split()
    title = title[0:3]
    title = ' '.join(title)
    titles_list.append(title)

    prices = soup.select('.n50 > h3 > span')
    prices_list = []
    for i, price in enumerate(prices):
        price = price.get_text()
    if len(price)> 2:
        price = price.replace(',','')
        try :
            price = int(price)
        except ValueError:
            price = str(price)    
        prices_list.append(price)

    locations = soup.select('.single-room-text > h4')
    locations_list = []
    for i in locations:
        loc = i.get_text().split()
    loc = loc[-2]
    loc = loc.replace(',', '')
    locations_list.append(loc)

    Amenities = soup.select('.fur-areea > span')
    toilet_list = []
    bath_list = []
    bed_list = []

    for i, a in enumerate(Amenities):
        if i in range(2,66,3):
            a = a.get_text().split()
            toilet = a[0]
            toilet_list.append(toilet)
        elif i in range(1,66,3):
            a = a.get_text().split()
            bath = a[0]
            bath_list.append(bath)
        elif i in range (0,66,3):
            a = a.get_text().split()
            bed = a[0]
            bed_list.append(bed)
    
    return(titles_list, prices_list, locations_list, toilet_list, bath_list, bed_list)

base_url = 'https://www.propertypro.ng/property-for-rent/in/lagos'
urls= [base_url]
for i in range(1,401):
    url = base_url + '?page=' + str(i)
    urls.append(url)

print(i)

master_titles = []
master_prices = []
master_locations = []
master_toilet = []
master_bath = []
master_bed = []

for url in urls:
    titles_list, prices_list, locations_list, toilet_list, bath_list, bed_list = scrape_page(url)
    
    master_titles += titles_list
    master_prices += prices_list
    master_locations += locations_list
    master_toilet += toilet_list
    master_bath += bath_list
    master_bed += bed_list

len(master_titles)